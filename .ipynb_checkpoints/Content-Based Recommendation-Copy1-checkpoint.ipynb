{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17ae0b03-c7ee-4fbd-a145-ae6a8061a20f",
   "metadata": {},
   "source": [
    "## AI/Machine Learning Intern Challenge: Simple Content-Based Recommendation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "7526488c-a1ec-4c8c-bd79-14243019b23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "fa186b71-afa0-4308-879d-0b45f3af0ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>filename</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>078.txt</td>\n",
       "      <td>Baby becomes new Oscar favourite</td>\n",
       "      <td>Clint Eastwood's boxing drama Million Dollar ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1412</th>\n",
       "      <td>sport</td>\n",
       "      <td>100.txt</td>\n",
       "      <td>Mido makes third apology</td>\n",
       "      <td>Ahmed 'Mido' Hossam has made another apology ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>239.txt</td>\n",
       "      <td>Fightstar take to the stage</td>\n",
       "      <td>Charlie Simpson took his new band Fightstar t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1706</th>\n",
       "      <td>sport</td>\n",
       "      <td>394.txt</td>\n",
       "      <td>Tindall wants second opinion</td>\n",
       "      <td>England centre Mike Tindall is to seek a seco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>249.txt</td>\n",
       "      <td>Soul sensation ready for awards</td>\n",
       "      <td>South West teenage singing sensation, Joss St...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           category filename                             title  \\\n",
       "587   entertainment  078.txt  Baby becomes new Oscar favourite   \n",
       "1412          sport  100.txt          Mido makes third apology   \n",
       "748   entertainment  239.txt       Fightstar take to the stage   \n",
       "1706          sport  394.txt      Tindall wants second opinion   \n",
       "758   entertainment  249.txt   Soul sensation ready for awards   \n",
       "\n",
       "                                                content  \n",
       "587    Clint Eastwood's boxing drama Million Dollar ...  \n",
       "1412   Ahmed 'Mido' Hossam has made another apology ...  \n",
       "748    Charlie Simpson took his new band Fightstar t...  \n",
       "1706   England centre Mike Tindall is to seek a seco...  \n",
       "758    South West teenage singing sensation, Joss St...  "
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('bbc-news-data.csv', sep='\\t').sample(500, random_state = 115)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "1afd3a69-f14e-4a15-b789-53a3b477212d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['entertainment', 'sport', 'politics', 'tech', 'business'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "24a5528b-02d8-4b1b-8992-58cf6d1039f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category    0\n",
       "filename    0\n",
       "title       0\n",
       "content     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking missing value\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "de8af1c3-33ea-49ed-8f2a-15d8a590b158",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/sally/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/sally/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: US economy shows solid GDP growth\n",
      "Cosine Similarity: 0.3506\n",
      "Content:  The US economy has grown more than expected, expanding at an annual rate of 3.8% in the last quarter of 2004.  The gross domestic product figure was ahead of the 3.1% the government estimated a month...\n",
      "--------------------------------------------------\n",
      "Title: Consumer spending lifts US growth\n",
      "Cosine Similarity: 0.2770\n",
      "Content:  US economic growth accelerated in the third quarter, helped by strong consumer spending, official figures have shown.  The economy expanded at an annual rate of 3.7% in the July to September period, ...\n",
      "--------------------------------------------------\n",
      "Title: Irish markets reach all-time high\n",
      "Cosine Similarity: 0.2017\n",
      "Content:  Irish shares have risen to a record high, with investors persuaded to buy into the market by low inflation and strong growth forecasts.  The ISEQ index of leading shares closed up 23 points to 6661.8...\n",
      "--------------------------------------------------\n",
      "Title: US data sparks inflation worries\n",
      "Cosine Similarity: 0.1929\n",
      "Content:  Wholesale prices in the US rose at the fastest rate in more than six years in January, according to government data.  New figures show the Labor Department producer price index (PPI) rose by 0.3% - i...\n",
      "--------------------------------------------------\n",
      "Title: Brazil jobless rate hits new low\n",
      "Cosine Similarity: 0.1730\n",
      "Content:  Brazil's unemployment rate fell to its lowest level in three years in December, according to the government.  The Brazilian Institute for Geography and Statistics (IBGE) said it fell to 9.6% in Decem...\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Initialize stemmer and stopwords\n",
    "stemmer = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Define a custom tokenizer that removes stopwords and stems\n",
    "def tokenize_and_stem(text):\n",
    "    words = word_tokenize(text.lower())  # Tokenize and lower case the text\n",
    "    filtered_words = [word for word in words if word not in stop_words and word.isalpha()]  # Remove stopwords and non-alphabetic words\n",
    "    return [stemmer.stem(word) for word in filtered_words]  # Stem the remaining words\n",
    "\n",
    "# Vectorize with the custom tokenizer\n",
    "vectorizer = TfidfVectorizer(stop_words=None, tokenizer=tokenize_and_stem)\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Example User Query\n",
    "user_query = \"economic forecasts and interest rates\"\n",
    "query_vector = vectorizer.transform([user_query])\n",
    "\n",
    "# Compute Cosine Similarity\n",
    "similarity_scores = cosine_similarity(query_vector, tfidf_matrix)\n",
    "\n",
    "# Find Top Matches\n",
    "top_indices = similarity_scores[0].argsort()[-5:][::-1]\n",
    "for idx in top_indices:\n",
    "    print(f\"Title: {df.iloc[idx]['title']}\")\n",
    "    print(f\"Cosine Similarity: {similarity_scores[0][idx]:.4f}\")\n",
    "    print(f\"Content: {df.iloc[idx]['content'][:200]}...\")  # First 200 characters\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "d258a499-1827-4754-8b84-6d936b6f07ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:406: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: US economy shows solid GDP growth\n",
      "Cosine Similarity: 0.3699\n",
      "Category: business\n",
      "Content:  The US economy has grown more than expected, expanding at an annual rate of 3.8% in the last quarter of 2004.  The gross domestic product figure was ahead of the 3.1% the government estimated a month...\n",
      "--------------------------------------------------\n",
      "Title: Consumer spending lifts US growth\n",
      "Cosine Similarity: 0.2968\n",
      "Category: business\n",
      "Content:  US economic growth accelerated in the third quarter, helped by strong consumer spending, official figures have shown.  The economy expanded at an annual rate of 3.7% in the July to September period, ...\n",
      "--------------------------------------------------\n",
      "Title: Irish markets reach all-time high\n",
      "Cosine Similarity: 0.2060\n",
      "Category: business\n",
      "Content:  Irish shares have risen to a record high, with investors persuaded to buy into the market by low inflation and strong growth forecasts.  The ISEQ index of leading shares closed up 23 points to 6661.8...\n",
      "--------------------------------------------------\n",
      "Title: Brazil jobless rate hits new low\n",
      "Cosine Similarity: 0.1952\n",
      "Category: business\n",
      "Content:  Brazil's unemployment rate fell to its lowest level in three years in December, according to the government.  The Brazilian Institute for Geography and Statistics (IBGE) said it fell to 9.6% in Decem...\n",
      "--------------------------------------------------\n",
      "Title: US data sparks inflation worries\n",
      "Cosine Similarity: 0.1848\n",
      "Category: business\n",
      "Content:  Wholesale prices in the US rose at the fastest rate in more than six years in January, according to government data.  New figures show the Labor Department producer price index (PPI) rose by 0.3% - i...\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "\n",
    "# Initialize stemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Define a custom tokenizer function that stems words\n",
    "def tokenize_and_stem(text):\n",
    "    words = word_tokenize(text)\n",
    "    return [stemmer.stem(word) for word in words]\n",
    "\n",
    "# Vectorize with stemming\n",
    "vectorizer = TfidfVectorizer(stop_words='english', tokenizer=tokenize_and_stem)\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Example User Query\n",
    "user_query = \"economic forecasts and interest rates\"\n",
    "query_vector = vectorizer.transform([user_query])\n",
    "\n",
    "# Compute Cosine Similarity\n",
    "similarity_scores = cosine_similarity(query_vector, tfidf_matrix)\n",
    "\n",
    "# Find Top Matches\n",
    "top_indices = similarity_scores[0].argsort()[-5:][::-1]\n",
    "for idx in top_indices:\n",
    "    print(f\"Title: {df.iloc[idx]['title']}\")\n",
    "    print(f\"Cosine Similarity: {similarity_scores[0][idx]:.4f}\")\n",
    "    print(f\"Category: {df.iloc[idx]['category']}\")\n",
    "    print(f\"Content: {df.iloc[idx]['content'][:200]}...\")  # First 200 characters\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "1a7afc24-163f-4c6d-9a88-7b832810c672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Matches:\n",
      "Title: Custody death rate 'shocks' MPs\n",
      "Category: politics\n",
      "Content: death in custody have reached shocking level committee of mp and peer ha warned the joint committee on human right found those committing suicide were mainly the most vulnerable with mental health dru...\n",
      "--------------------------------------------------\n",
      "Title: MPs to debate 'euthanasia laws'\n",
      "Category: politics\n",
      "Content: mp are preparing to debate bill which critic claim would legalise euthanasia by the back door the bill would give legal force to living will where people say they want medical treatment withheld if th...\n",
      "--------------------------------------------------\n",
      "Title: Blair looks to election campaign\n",
      "Category: politics\n",
      "Content: tony blair big speech will be looked back on a the performance that kicked off the election campaign that poll may still be about week away but there can be little doubt left that the campaign is now ...\n",
      "--------------------------------------------------\n",
      "Title: Soderling wins tense Milan final\n",
      "Category: sport\n",
      "Content: fifth seed robin soderling took the milan indoors title with dramatic win over radek stepanek in sunday final the 20yearold swede edged the final set tiebreak for victory and his second tour title aft...\n",
      "--------------------------------------------------\n",
      "Title: Businesses fail to plan for HIV\n",
      "Category: business\n",
      "Content: company fail to draw up plan to cope with hivaids until it affect of people in country new research say the finding come in report published on thursday by the world economic forum harvard and the un ...\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Preprocessing: Focus on the 'content' column\n",
    "documents = df['content'].tolist()\n",
    "\n",
    "# Step 1: Vectorize the text using TF-IDF\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Example User Query\n",
    "user_query = \"the importance of mental health.\"\n",
    "query_vector = vectorizer.transform([user_query])\n",
    "\n",
    "# Step 2: Compute Cosine Similarity\n",
    "similarity_scores = cosine_similarity(query_vector, tfidf_matrix)\n",
    "\n",
    "# Step 3: Find Top Matches\n",
    "top_indices = similarity_scores[0].argsort()[-5:][::-1]\n",
    "print(\"Top Matches:\")\n",
    "for idx in top_indices:\n",
    "    print(f\"Title: {df.iloc[idx]['title']}\")\n",
    "    print(f\"Category: {df.iloc[idx]['category']}\")\n",
    "    print(f\"Content: {df.iloc[idx]['content'][:200]}...\")  # First 200 characters\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "edccde79-6470-47d5-8323-71e1ccea950a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Matches:\n",
      "Title: Custody death rate 'shocks' MPs\n",
      "Category: politics\n",
      "Cosine Similarity: 0.1430\n",
      "Content: death in custody have reached shocking level committee of mp and peer ha warned the joint committee on human right found those committing suicide were mainly the most vulnerable with mental health dru...\n",
      "--------------------------------------------------\n",
      "Title: MPs to debate 'euthanasia laws'\n",
      "Category: politics\n",
      "Cosine Similarity: 0.1111\n",
      "Content: mp are preparing to debate bill which critic claim would legalise euthanasia by the back door the bill would give legal force to living will where people say they want medical treatment withheld if th...\n",
      "--------------------------------------------------\n",
      "Title: Blair looks to election campaign\n",
      "Category: politics\n",
      "Cosine Similarity: 0.0631\n",
      "Content: tony blair big speech will be looked back on a the performance that kicked off the election campaign that poll may still be about week away but there can be little doubt left that the campaign is now ...\n",
      "--------------------------------------------------\n",
      "Title: Soderling wins tense Milan final\n",
      "Category: sport\n",
      "Cosine Similarity: 0.0631\n",
      "Content: fifth seed robin soderling took the milan indoors title with dramatic win over radek stepanek in sunday final the 20yearold swede edged the final set tiebreak for victory and his second tour title aft...\n",
      "--------------------------------------------------\n",
      "Title: Businesses fail to plan for HIV\n",
      "Category: business\n",
      "Cosine Similarity: 0.0482\n",
      "Content: company fail to draw up plan to cope with hivaids until it affect of people in country new research say the finding come in report published on thursday by the world economic forum harvard and the un ...\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Preprocessing: Focus on the 'content' column\n",
    "documents = df['content'].tolist()\n",
    "\n",
    "# Step 1: Vectorize the text using TF-IDF\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Example User Query\n",
    "user_query = \"the importance of mental health.\"\n",
    "query_vector = vectorizer.transform([user_query])\n",
    "\n",
    "# Step 2: Compute Cosine Similarity\n",
    "similarity_scores = cosine_similarity(query_vector, tfidf_matrix)\n",
    "\n",
    "# Step 3: Find Top Matches\n",
    "top_indices = similarity_scores[0].argsort()[-5:][::-1]\n",
    "\n",
    "print(\"Top Matches:\")\n",
    "for idx in top_indices:\n",
    "    print(f\"Title: {df.iloc[idx]['title']}\")\n",
    "    print(f\"Category: {df.iloc[idx]['category']}\")\n",
    "    print(f\"Cosine Similarity: {similarity_scores[0][idx]:.4f}\")  # Display cosine similarity\n",
    "    print(f\"Content: {df.iloc[idx]['content'][:200]}...\")  # First 200 characters\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "e92f360b-b10d-486b-9376-e45798c56180",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing text first\n",
    "\n",
    "import re\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "\n",
    "lemmatizer= WordNetLemmatizer()\n",
    "\n",
    "#Function\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Cleans the input text by performing multiple NLP preprocessing steps.\"\"\"\n",
    "    \n",
    "    # lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove the pound sign from hash tags\n",
    "    text = re.sub(r'#', '', text)\n",
    "    \n",
    "    # Remove punctuation and special characters\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    # Remove standalone numbers but keep mixed alphanumeric terms\n",
    "    text = re.sub(r'\\b\\d+\\b', '', text) \n",
    "    \n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # drop words with fewer than 2 characters\n",
    "    tokens = [word for word in tokens if len(word) >= 2]\n",
    "\n",
    "\n",
    "    # lemmatization\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    \n",
    "    return ' '.join(tokens)\n",
    "\n",
    "\n",
    "df['content']= df['content'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "5a7c081c-1355-48f0-b8eb-502e2dbbaead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "587     clint eastwoods boxing drama million dollar ba...\n",
       "1412    ahmed mido hossam ha made another apology to t...\n",
       "748     charlie simpson took his new band fightstar to...\n",
       "1706    england centre mike tindall is to seek second ...\n",
       "758     south west teenage singing sensation joss ston...\n",
       "                              ...                        \n",
       "2120    apple ha unveiled new lowcost macintosh comput...\n",
       "1545    southampton are set to unveil harry redknapp a...\n",
       "1390    britain kathy butler continued her impressive ...\n",
       "1626    two moment of magic from brian odriscoll guide...\n",
       "2134    the bbc news website take look at how game on ...\n",
       "Name: content, Length: 500, dtype: object"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "00ef2490-9643-4708-b33f-0fbdc402e158",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "\n",
    "def compute_cosine_similarity(df, text_column):\n",
    "    \"\"\"\n",
    "    Compute TF-IDF vectors and cosine similarity for text data.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The input dataframe.\n",
    "        text_column (str): The name of the column containing text data.\n",
    "\n",
    "    Returns:\n",
    "        similarity_matrix (pd.DataFrame): A dataframe representing cosine similarity between items.\n",
    "    \"\"\"\n",
    "    # Initialize the TF-IDF vectorizer\n",
    "    vectorizer = TfidfVectorizer()  # Limit features for efficiency\n",
    "    \n",
    "    # Transform the text data into TF-IDF vectors\n",
    "    tfidf_matrix = vectorizer.fit_transform(df[text_column])\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    similarity_matrix = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "    \n",
    "    # Convert the similarity matrix into a DataFrame for better readability\n",
    "    similarity_df = pd.DataFrame(\n",
    "        similarity_matrix,\n",
    "        index=df.index,\n",
    "        columns=df.index\n",
    "    )\n",
    "    \n",
    "    return similarity_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "d11631d4-fa39-491e-8db3-16bb7857370a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          587       1412      748       1706      758       1026      2102  \\\n",
      "587   1.000000  0.116760  0.096446  0.111056  0.170354  0.103905  0.119693   \n",
      "1412  0.116760  1.000000  0.122431  0.146032  0.079413  0.152531  0.140081   \n",
      "748   0.096446  0.122431  1.000000  0.096227  0.080912  0.127676  0.105322   \n",
      "1706  0.111056  0.146032  0.096227  1.000000  0.069349  0.133717  0.107287   \n",
      "758   0.170354  0.079413  0.080912  0.069349  1.000000  0.101771  0.074881   \n",
      "\n",
      "          497       776       481   ...      609       543       371   \\\n",
      "587   0.091422  0.149624  0.125961  ...  0.149723  0.203143  0.116716   \n",
      "1412  0.104110  0.139836  0.144173  ...  0.123234  0.114374  0.098386   \n",
      "748   0.093486  0.163899  0.117026  ...  0.130256  0.110010  0.098283   \n",
      "1706  0.089449  0.110438  0.109919  ...  0.105268  0.090734  0.082520   \n",
      "758   0.082950  0.152081  0.091993  ...  0.103490  0.156747  0.077121   \n",
      "\n",
      "          1159      1638      2120      1545      1390      1626      2134  \n",
      "587   0.181274  0.127832  0.120309  0.100397  0.120686  0.104577  0.156860  \n",
      "1412  0.198736  0.172685  0.129948  0.145919  0.090813  0.109221  0.181460  \n",
      "748   0.167656  0.114611  0.113298  0.096176  0.079837  0.117383  0.150910  \n",
      "1706  0.167687  0.299560  0.103590  0.111643  0.067728  0.106431  0.152405  \n",
      "758   0.123797  0.076748  0.099749  0.078766  0.101198  0.079238  0.094279  \n",
      "\n",
      "[5 rows x 500 columns]\n"
     ]
    }
   ],
   "source": [
    "# new Compute cosine similarity for the 'content' column\n",
    "similarity_df = compute_cosine_similarity(df, text_column='content')\n",
    "\n",
    "# Display the similarity matrix\n",
    "print(similarity_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "c2766d26-5281-4356-b112-c503af4cea55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(df, text_column, query, k=5):\n",
    "    \"\"\"\n",
    "    Search for the most similar items to a user query based on cosine similarity.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The input dataframe.\n",
    "        text_column (str): The name of the column containing text data.\n",
    "        query (str): The user's search query.\n",
    "        k (int): The number of top recommendations to return.\n",
    "        \n",
    "    Returns:\n",
    "        recommendations (pd.DataFrame): A dataframe with the top k recommended items.\n",
    "    \"\"\"\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    \n",
    "    # Combine the query with the existing content\n",
    "    combined_text = df[text_column].tolist() + [query]\n",
    "    \n",
    "    # Initialize the TF-IDF vectorizer and transform the text\n",
    "    vectorizer = TfidfVectorizer(max_features=5000)\n",
    "    tfidf_matrix = vectorizer.fit_transform(combined_text)\n",
    "    \n",
    "    # Compute cosine similarity between the query and all items\n",
    "    similarity_scores = cosine_similarity(tfidf_matrix[-1:], tfidf_matrix[:-1]).flatten()\n",
    "    \n",
    "    # Get the top k similar items\n",
    "    top_indices = similarity_scores.argsort()[-k:][::-1]  # Indices of top k items\n",
    "    recommendations = df.iloc[top_indices].copy()  # Explicitly create a copy\n",
    "    recommendations['similarity'] = similarity_scores[top_indices]\n",
    "    \n",
    "    return recommendations[['title', 'category', 'similarity']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "52fe8fb4-6756-4ce8-ae8f-ae91cef7353b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>Man Utd to open books to Glazer</td>\n",
       "      <td>business</td>\n",
       "      <td>0.161400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>UK's 'useless' quangos under fire</td>\n",
       "      <td>politics</td>\n",
       "      <td>0.155736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>Funding cut hits Wales Students</td>\n",
       "      <td>sport</td>\n",
       "      <td>0.127849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>'My memories of Marley...'</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>0.071390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1935</th>\n",
       "      <td>Portable PlayStation ready to go</td>\n",
       "      <td>tech</td>\n",
       "      <td>0.062236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  title       category  similarity\n",
       "223     Man Utd to open books to Glazer       business    0.161400\n",
       "980   UK's 'useless' quangos under fire       politics    0.155736\n",
       "1674    Funding cut hits Wales Students          sport    0.127849\n",
       "629          'My memories of Marley...'  entertainment    0.071390\n",
       "1935   Portable PlayStation ready to go           tech    0.062236"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sport:\n",
    "\n",
    "\n",
    "user_query = \"football scores\"\n",
    "\n",
    "# Search for top 5 recommendations\n",
    "results = search(df, text_column='content', query=user_query, k=5)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "e4e55e0c-b69e-4ed4-b975-db4d486fe44f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1175</th>\n",
       "      <td>Blair sees greater Bush consensus</td>\n",
       "      <td>politics</td>\n",
       "      <td>0.165449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1162</th>\n",
       "      <td>UKIP's secret weapon?</td>\n",
       "      <td>politics</td>\n",
       "      <td>0.132568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>Faith schools citizenship warning</td>\n",
       "      <td>politics</td>\n",
       "      <td>0.126330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>New foot and mouth action urged</td>\n",
       "      <td>politics</td>\n",
       "      <td>0.124972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>Economy focus for election battle</td>\n",
       "      <td>politics</td>\n",
       "      <td>0.110837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  title  category  similarity\n",
       "1175  Blair sees greater Bush consensus  politics    0.165449\n",
       "1162              UKIP's secret weapon?  politics    0.132568\n",
       "1067  Faith schools citizenship warning  politics    0.126330\n",
       "1098    New foot and mouth action urged  politics    0.124972\n",
       "1289  Economy focus for election battle  politics    0.110837"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Politics:\n",
    "\n",
    "\n",
    "\n",
    "user_query = \"the future of democracy\"\n",
    "\n",
    "# Search for top 5 recommendations\n",
    "results = search(df, text_column='content', query=user_query, k=5)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "6931280c-5254-4071-b545-704e389c06e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>New foot and mouth action urged</td>\n",
       "      <td>politics</td>\n",
       "      <td>0.228383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>Economy focus for election battle</td>\n",
       "      <td>politics</td>\n",
       "      <td>0.199213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>Ronaldo considering new contract</td>\n",
       "      <td>sport</td>\n",
       "      <td>0.196550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2049</th>\n",
       "      <td>Millions to miss out on the net</td>\n",
       "      <td>tech</td>\n",
       "      <td>0.194739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Europe blames US over weak dollar</td>\n",
       "      <td>business</td>\n",
       "      <td>0.193982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  title  category  similarity\n",
       "1098    New foot and mouth action urged  politics    0.228383\n",
       "1289  Economy focus for election battle  politics    0.199213\n",
       "1410   Ronaldo considering new contract     sport    0.196550\n",
       "2049    Millions to miss out on the net      tech    0.194739\n",
       "88    Europe blames US over weak dollar  business    0.193982"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Business:\n",
    "\n",
    "user_query = \"the future of cryptocurrency\"\n",
    "\n",
    "# Search for top 5 recommendations\n",
    "results = search(df, text_column='content', query=user_query, k=5)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "d31c6cad-4d33-4594-948e-44af1d8cf626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>Bets off after Big Brother 'leak'</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>0.268556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>Greer attacks 'bully' Big Brother</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>0.245264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>Double eviction from Big Brother</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>0.079396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>Eminem beats Elvis to number one</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>0.068220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>McCririck out of Big Brother show</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>0.066285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 title       category  similarity\n",
       "730  Bets off after Big Brother 'leak'  entertainment    0.268556\n",
       "712  Greer attacks 'bully' Big Brother  entertainment    0.245264\n",
       "696   Double eviction from Big Brother  entertainment    0.079396\n",
       "653   Eminem beats Elvis to number one  entertainment    0.068220\n",
       "689  McCririck out of Big Brother show  entertainment    0.066285"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entertainment:\n",
    "\n",
    "\n",
    "user_query = \"Big Brother\"\n",
    "\n",
    "# Search for top 5 recommendations\n",
    "results = search(df, text_column='content', query=user_query, k=5)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d808260-1c12-4a9b-aee0-1f1546cedf81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
